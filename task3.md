# ДЗ №3

Есть набор данных формата вопрос-ответ. На этих данных нужно построить Retrieval-систему, которая будет искать релевантные ответы по запросу пользователя.

## Общее

В качестве набора данных используйте этот датасет: https://huggingface.co/datasets/sentence-transformers/natural-questions . Разбейте его на train/test в пропорции 80%/20%.

## Задача 1. Метрики

1. Реализуйте функцию для расчёта метрики Recall@K. Эта метрика показывает, какая доля вопросов содержит в ТОП-K выдачи правильный документ. Функция должна принимать: а) target - ID правильного документа к каждому запросу; б) predict - отсортированные по релевантности (метрике близости) ID документов к каждому запросу. Функция должна вернуть число - значение метрики.
2. По такому же принципу реализуйте функцию для расчёта метрики [MRR](https://en.wikipedia.org/wiki/Mean_reciprocal_rank).


## Задача 2. TF-IDF Baseline

1. Настройте алгоритм [TF-IDF](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) на обучающей выборке.
2. При помощи уже настроенного TF-IDF векторизуйте вопросы и документы из тестовой выборки.
3. При помощи метрики близости Cosine Similarity сделайте ранжирование документов из тестовой выборки для каждого вопроса из тестовой выборки.
4. Рассчитайте метрики MRR и Recall@1, Recall@3, Recall@10.

Вопросы:
1. Какие получились метрики? Что можно о них сказать?
2. Какие ограничения есть у текущего подхода?


## Задача 3. E5 Baseline

1. При помощи уже обученной модели [Multilingual-E5-Base](https://huggingface.co/intfloat/multilingual-e5-base) векторизуйте вопросы и документы из тестовой выборки.
2. При помощи метрики близости Cosine Similarity сделайте ранжирование документов из тестовой выборки для каждого вопроса из тестовой выборки.
3. Рассчитайте метрики MRR и Recall@1, Recall@3, Recall@10.

Вопросы:
1. Какие получились метрики? Что можно о них сказать?
2. Стало ли лучше в сравнении с TF-IDF? Почему?


## Задача 4. E5 Train

Дообучите модель [Multilingual-E5-Base](https://huggingface.co/intfloat/multilingual-e5-base):
1. На Contrastive Loss. Contrastive Loss работает с двумя элементами. Как первый элемент берите вопрос. Как второй элемент берите документ. Если хотите сделать positive пару - документ нужно брать соответствующий вопросу. Если хотите сделать negative пару - берите случайный документ из обучающей выборки.
2. На Triplet Loss. Triplet Loss работает с тройками anchor, positive, negative. Как anchor берите вопрос. Как positive берите соответствующий документ. Как negative берите случайный документ из обучающей выборки.

Далее для двух моделей:
1. При помощи обученной модели векторизуйте вопросы и документы из тестовой выборки.
2. При помощи метрики близости Cosine Similarity сделайте ранжирование документов из тестовой выборки для каждого вопроса из тестовой выборки.
3. Рассчитайте метрики MRR и Recall@1, Recall@3, Recall@10.

Вопросы:
1. Какие получились метрики? Что можно о них сказать? 
2. Что сработало лучше - Contrastive Loss или Triplet Loss? Почему?
3. Стало ли лучше в сравнении с ванильным E5? Почему?


## Задача 5. E5 Train with Hard Negatives

1. Дообучите модель [Multilingual-E5-Base](https://huggingface.co/intfloat/multilingual-e5-base) на Triplet Loss. Но, в отличие от предыдущего задания, в качестве negative берите не случайный документ, а документ, который близок к запросу.
2. При помощи обученной модели векторизуйте вопросы и документы из тестовой выборки.
3. При помощи метрики близости Cosine Similarity сделайте ранжирование документов из тестовой выборки для каждого вопроса из тестовой выборки.
4. Рассчитайте метрики MRR и Recall@1, Recall@3, Recall@10.

Вопросы:
1. Какие получились метрики? Что можно о них сказать?
2. Стало ли лучше в сравнении с random negatives? Почему?

## Сдача

Код для воспроизведения результатов (чтобы можно было запустить разные .py-файлы и воспроизвести результаты) в виде ссылки на GitHub репозиторий нужно отправить мне в личку в телеграм.
В readme.md в репозитории укажите значения метрик и ответы на вопросы с небольшим пояснением для каждой задачи.

### Баллы
* 1-2 задачи: 3 балла
* 1-4 задачи: 4 балла
* 1-5 задачи: 5 баллов

### Дедлайн

Сдавать и корректировать решение можно до 25 мая.
